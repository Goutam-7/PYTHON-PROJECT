{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3843a78-ede8-4a18-8ee4-32f4e0f06c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d0708cc-8836-47f9-be9f-05dd083dd5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26762a7a-fe1a-43c8-8768-4bc4f2545fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81e1744c-6f83-47fc-97d4-79f0cc7bae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets into variables\n",
    "TrainingDataset = pd.read_csv('TrainingDataset.csv')\n",
    "TestDataset = pd.read_csv('TestDataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3f275e6-0d76-4f4e-bbf5-1b757aa44ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the datasets are already loaded into variables\n",
    "# TrainingDataset = pd.read_csv('path_to_training_dataset.csv')\n",
    "# TestDataset = pd.read_csv('path_to_test_dataset.csv')\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "training_data_encoded = pd.get_dummies(TrainingDataset.drop('Loan_ID', axis=1))\n",
    "test_data_encoded = pd.get_dummies(TestDataset.drop('Loan_ID', axis=1))\n",
    "\n",
    "# Ensure both datasets have the same columns\n",
    "train_columns = training_data_encoded.columns\n",
    "test_columns = test_data_encoded.columns\n",
    "\n",
    "# Add any missing columns to test_data_encoded\n",
    "for column in train_columns:\n",
    "    if column not in test_columns:\n",
    "        test_data_encoded[column] = 0\n",
    "\n",
    "# Ensure the columns are in the same order\n",
    "# Exclude 'Loan_Status_Y' from train_columns for test_data alignment\n",
    "train_columns_without_target = train_columns.drop('Loan_Status_Y', errors='ignore')\n",
    "test_data_encoded = test_data_encoded[train_columns_without_target]\n",
    "\n",
    "# Separate features and target variable from the training data\n",
    "X_train = training_data_encoded.drop('Loan_Status_Y', axis=1, errors='ignore')\n",
    "y_train = training_data_encoded['Loan_Status_Y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b604f4a5-ef5b-494a-8ccf-66624f1f8115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the datasets\n",
    "TrainingDataset = pd.read_csv('TrainingDataset.csv')\n",
    "TestDataset = pd.read_csv('TestDataset.csv')\n",
    "\n",
    "# Handle missing values\n",
    "# Fill missing categorical values with mode\n",
    "for column in ['Gender', 'Married', 'Dependents', 'Self_Employed']:\n",
    "    TrainingDataset[column].fillna(TrainingDataset[column].mode()[0], inplace=True)\n",
    "    TestDataset[column].fillna(TestDataset[column].mode()[0], inplace=True)\n",
    "\n",
    "# Fill missing numerical values with median\n",
    "TrainingDataset['LoanAmount'].fillna(TrainingDataset['LoanAmount'].median(), inplace=True)\n",
    "TestDataset['LoanAmount'].fillna(TestDataset['LoanAmount'].median(), inplace=True)\n",
    "\n",
    "TrainingDataset['Loan_Amount_Term'].fillna(TrainingDataset['Loan_Amount_Term'].median(), inplace=True)\n",
    "TestDataset['Loan_Amount_Term'].fillna(TestDataset['Loan_Amount_Term'].median(), inplace=True)\n",
    "\n",
    "TrainingDataset['Credit_History'].fillna(TrainingDataset['Credit_History'].mode()[0], inplace=True)\n",
    "TestDataset['Credit_History'].fillna(TestDataset['Credit_History'].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical variables using one-hot encoding\n",
    "training_data_encoded = pd.get_dummies(TrainingDataset.drop('Loan_ID', axis=1))\n",
    "test_data_encoded = pd.get_dummies(TestDataset.drop('Loan_ID', axis=1))\n",
    "\n",
    "# Ensure both datasets have the same columns\n",
    "train_columns = training_data_encoded.columns\n",
    "test_columns = test_data_encoded.columns\n",
    "\n",
    "# Add any missing columns to test_data_encoded\n",
    "for column in train_columns:\n",
    "    if column not in test_columns:\n",
    "        test_data_encoded[column] = 0\n",
    "\n",
    "# Ensure the columns are in the same order\n",
    "# Exclude 'Loan_Status_Y' from train_columns for test_data alignment\n",
    "train_columns_without_target = train_columns.drop('Loan_Status_Y', errors='ignore')\n",
    "test_data_encoded = test_data_encoded[train_columns_without_target]\n",
    "\n",
    "# Separate features and target variable from the training data\n",
    "X_train = training_data_encoded.drop('Loan_Status_Y', axis=1, errors='ignore')\n",
    "y_train = training_data_encoded['Loan_Status_Y']\n",
    "\n",
    "# Split the data for training and validation\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Validate the model\n",
    "y_pred_val = model.predict(X_val_split)\n",
    "accuracy = accuracy_score(y_val_split, y_pred_val)\n",
    "print(f'Validation Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "test_predictions = model.predict(test_data_encoded)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'Loan_ID': TestDataset['Loan_ID'],\n",
    "    'Loan_Status': ['Y' if pred == 1 else 'N' for pred in test_predictions]\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b344d8-fbfd-4945-b0e0-332703d75a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
